# Pipeline Architecture - Visual Guide

## Before vs After

### BEFORE (Single Pipeline)
```
Cron (Hourly)
    â†“
run_scraper_pipeline.py
    â”œâ”€ Stage 1: Fetch (15-30 min)
    â”œâ”€ Stage 2: Parse (5-10 min)
    â”œâ”€ Stage 3: Download Pages (30-60 min) â† Heavy operation
    â””â”€ Stage 4: Generate API (1-5 min)
    
Total: 60-120 minutes (often timeout!)
Problem: Heavy download stage slowing down cron
```

### AFTER (Split Pipelines)
```
Cron (Hourly)
    â†“
run_cron_pipeline.py
    â”œâ”€ Stage 1: Fetch (15-30 min)
    â”œâ”€ Stage 2: Parse (5-10 min) â† Logs parsed_jobs count
    â””â”€ Done!
    
Total: 20-40 minutes âœ…

Manual (When needed)
    â†“
run_scraper_pipeline.py
    â”œâ”€ Stage 1: Fetch
    â”œâ”€ Stage 2: Parse
    â”œâ”€ Stage 3: Download Pages (heavy)
    â””â”€ Stage 4: Generate API
```

## Data Flow

```
CRON EXECUTION (Every Hour)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1ï¸âƒ£  FETCH MAIN PAGE (Stage 1)                                  â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚ â€¢ Use Playwright to browse lobbyx.army                          â”‚
â”‚ â€¢ Click "Load More" button (with safeguards)                   â”‚
â”‚ â€¢ Save complete HTML with all jobs loaded                      â”‚
â”‚ â€¢ Output: data/YYYY/MM/DD/output_HHMMSS.html                  â”‚
â”‚ â€¢ Time: 15-30 minutes                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2ï¸âƒ£  PARSE HTML TO JSON (Stage 2)                              â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚ â€¢ Extract job listings from HTML                               â”‚
â”‚ â€¢ Parse job data (ID, position, unit, category, status)      â”‚
â”‚ â€¢ Save structured JSON data                                    â”‚
â”‚ â€¢ Output: data/YYYY/MM/DD/output_HHMMSS.json                 â”‚
â”‚ â€¢ Time: 5-10 minutes                                            â”‚
â”‚                                                                 â”‚
â”‚ ğŸ“Š LOG STATISTICS:                                             â”‚
â”‚    â”œâ”€ parsed_jobs count                                        â”‚
â”‚    â”œâ”€ timestamp                                                â”‚
â”‚    â””â”€ Save to: logs/cron_stats.jsonl                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
                    âœ… DONE
             Total Time: 20-40 minutes
```

## Statistics File Format

```json
// logs/cron_stats.jsonl (one entry per line)

{"timestamp": "2025-12-16T10:00:00.123456", "parsed_jobs": 42}
{"timestamp": "2025-12-16T11:00:00.234567", "parsed_jobs": 38}
{"timestamp": "2025-12-16T12:00:00.345678", "parsed_jobs": 35}
{"timestamp": "2025-12-16T13:00:00.345789", "parsed_jobs": 40}
```

## Playwright Click Loop (Stage 1)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Navigate to lobbyx.army                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Attempt = 0  â”‚
            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Attempt += 1                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Button has class="done"?         â”‚
    â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
  Yes  â”‚  No
       â”‚  â”œâ”€â†’ Click button
       â”‚  â”œâ”€â†’ Wait 2 seconds (AJAX)
       â”‚  â”œâ”€â†’ Increment attempt
       â”‚  â””â”€â†’ Check loop condition
       â”‚
  â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Attempt >= max_attempts (100)? â”‚
  â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
 No  â”‚  Yes
     â”‚  â”œâ”€â†’ Stop (safeguard)
     â”‚  â””â”€â†’ Log warning
     â”‚
     â””â”€â†’ âœ… Page fully loaded
```

## File Organization

```
Repository/
â”œâ”€â”€ run_cron_pipeline.py          â† New: Cron pipeline (2 stages)
â”œâ”€â”€ run_scraper_pipeline.py       â† Full pipeline (4 stages)
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ 1_fetch_main_page.py          (improved Playwright)
â”‚   â”œâ”€â”€ 2_parse_html_to_json.py       (logs stats)
â”‚   â”œâ”€â”€ 3_download_job_pages.py       (not in cron)
â”‚   â””â”€â”€ 4_generate_dashboard_api.py   (not in cron)
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ cron_wrapper.sh           (updated for cron pipeline)
â”‚
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ cron_stats.jsonl          â† Statistics from cron
â”‚   â””â”€â”€ debug.log
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ YYYY/MM/DD/
â”‚   â”‚   â”œâ”€â”€ output_*.html         (Stage 1)
â”‚   â”‚   â””â”€â”€ output_*.json         (Stage 2)
â”‚   â”‚
â”‚   â””â”€â”€ job-pages/                (Stage 3 - not in cron)
â”‚       â””â”€â”€ {ID:3}/{ID:3}/
â”‚           â”œâ”€â”€ job_*.html
â”‚           â””â”€â”€ job_*.json
â”‚
â””â”€â”€ api/                          (Stage 4 - not in cron)
    â””â”€â”€ list-json-files.json
```

## Execution Timeline

```
HOURLY CRON EXECUTION (Typical Flow)

10:00:00 - Cron triggered
10:00:01 - run_cron_pipeline.py starts
10:00:02 - Stage 1: Fetch begins
          â””â”€ Launch browser
          â””â”€ Navigate to lobbyx.army
          â””â”€ Click "Load More" 10-20 times
          â””â”€ Save HTML to data/2025/12/16/output_100020.html
10:15:00 - Stage 1: Complete (15 min)
10:15:01 - Stage 2: Parse begins
          â””â”€ Read HTML files
          â””â”€ Extract 42 jobs
          â””â”€ Save JSON to data/2025/12/16/output_100020.json
          â””â”€ Call log_cron_stats(42)
          â””â”€ Append to logs/cron_stats.jsonl
10:20:00 - Stage 2: Complete (5 min)
10:20:01 - Pipeline ends
          â””â”€ Total time: 20 minutes âœ…
          â””â”€ Cron moves to next tasks
```

## Statistics Viewing

```bash
# View cron stats (default: last 10 runs)
$ python3 tools/view_cron_stats.py
Shows timestamps and parsed_jobs counts

# View specific number of runs
$ python3 tools/view_cron_stats.py --last 20
Shows last 20 runs

# Analyze trends
$ python3 tools/analyze_cron_stats.py
Shows statistics, timeline, charts
```

## Key Improvements

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CRON PERFORMANCE                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚ âŒ Before:  60-120 minutes                             â”‚
â”‚    â””â”€ Stage 3 (download) blocked cron                  â”‚
â”‚    â””â”€ Often timed out                                  â”‚
â”‚    â””â”€ Stats only logged on success                     â”‚
â”‚                                                         â”‚
â”‚ âœ… After:   20-40 minutes                              â”‚
â”‚    â””â”€ Light stages only (fetch + parse)               â”‚
â”‚    â””â”€ Never times out                                  â”‚
â”‚    â””â”€ Stats logged every run                           â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

**Architecture:** Modular pipeline with split cron/manual execution  
**Performance:** 50% faster cron execution  
**Reliability:** Safeguards for Playwright clicking  
**Visibility:** Every cron run tracked in statistics  

---

*Visual Guide - Reference Material*  
*Last Updated: 2025-12-16*
